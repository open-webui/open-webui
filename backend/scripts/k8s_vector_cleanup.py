#!/usr/bin/env python3
"""
Kubernetes Vector Database Cleanup Script for CANChat
Runs comprehensive cleanup of orphaned vectors while preserving knowledge bases.
"""

import os
import sys
import logging
import argparse
from datetime import datetime

# Add the current directory to Python path (we're in /app/scripts, backend is at /app)
sys.path.insert(0, "/app")


def setup_logging(verbose=False):
    """Configure logging for K8s environment."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    return logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(
        description="CANChat Vector DB Cleanup for Kubernetes"
    )
    parser.add_argument(
        "--verbose", "-v", action="store_true", help="Enable verbose logging"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be cleaned without making changes",
    )
    args = parser.parse_args()

    logger = setup_logging(args.verbose)

    logger.info("üßπ Starting CANChat Vector Database Cleanup")
    logger.info(f"Timestamp: {datetime.now().isoformat()}")
    logger.info(f"Dry run mode: {args.dry_run}")

    # Detect database configuration
    database_url = os.getenv("DATABASE_URL")
    if database_url:
        if database_url.startswith("postgresql://") or database_url.startswith(
            "postgres://"
        ):
            db_type = "PostgreSQL"
            logger.info(
                f"üóÑÔ∏è  Database: {db_type} - {database_url.split('@')[1] if '@' in database_url else 'configured'}"
            )
        elif database_url.startswith("sqlite:///"):
            db_type = "SQLite"
            logger.info(f"üóÑÔ∏è  Database: {db_type} - {database_url}")
        else:
            db_type = "Unknown"
            logger.warning(f"‚ö†Ô∏è  Unknown database type: {database_url}")
    else:
        db_type = "SQLite (default)"
        logger.info(f"üóÑÔ∏è  Database: {db_type} - Using default SQLite")

    try:
        # Validate environment configuration
        logger.info("üîß Validating environment configuration...")

        # Check critical environment variables
        required_vars = ["QDRANT_URI"]
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        if missing_vars:
            logger.error(f"‚ùå Missing required environment variables: {missing_vars}")
            return 1

        # Log vector database configuration
        qdrant_uri = os.getenv("QDRANT_URI")
        logger.info(f"üîç Qdrant URI: {qdrant_uri}")

        # Log other relevant settings
        if os.getenv("QDRANT_API_KEY"):
            logger.info("üîê Qdrant API key: Configured")

        data_dir = os.getenv("DATA_DIR", "/app/backend/data")
        upload_dir = os.getenv("UPLOAD_DIR", "/app/backend/data/uploads")
        logger.info(f"üìÅ Data directory: {data_dir}")
        logger.info(f"üìÅ Upload directory: {upload_dir}")

        # Log cleanup configuration
        web_search_expiry_days = int(os.getenv("VECTOR_DB_WEB_SEARCH_EXPIRY_DAYS", "7"))
        collection_cleanup_days = int(
            os.getenv("VECTOR_DB_COLLECTION_CLEANUP_DAYS", "1")
        )
        logger.info(f"‚è∞ Web search cleanup: {web_search_expiry_days} days retention")
        logger.info(
            f"‚è∞ Collection cleanup: {collection_cleanup_days} days retention (prevents uncontrolled growth)"
        )

        logger.info("‚úì Environment validation completed")

        # Import cleanup functions
        from open_webui.routers.retrieval import (
            cleanup_orphaned_vectors,
            cleanup_expired_web_searches,
            cleanup_orphaned_chat_files,
            cleanup_orphaned_files_by_reference,
            cleanup_old_chat_collections,
            cleanup_expired_chats,
        )
        from open_webui.models.knowledge import Knowledges
        from open_webui.config import CHAT_LIFETIME_ENABLED, CHAT_LIFETIME_DAYS

        logger.info("‚úì Successfully imported cleanup modules")

        # Test database connectivity
        logger.info("üîå Testing database connectivity...")
        try:
            # Try to get knowledge bases as a connectivity test
            knowledge_bases = Knowledges.get_knowledge_bases()
            logger.info(f"‚úì Database connection successful")
            logger.info(f"üìä Found {len(knowledge_bases)} knowledge bases to preserve")
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            logger.error(
                "This could indicate database connectivity issues or missing credentials"
            )
            return 1

        # Run cleanup operations
        cleanup_results = {}

        # 1. Clean up orphaned standalone files
        logger.info("üîç Cleaning orphaned standalone files...")
        if not args.dry_run:
            result = cleanup_orphaned_vectors()
            cleanup_results["orphaned_files"] = result
            logger.info(f"‚úì Orphaned files cleanup: {result}")
        else:
            logger.info("‚úì [DRY RUN] Would clean orphaned standalone files")

        # 2. Clean up files not referenced by any chats (safe for cloned chats)
        logger.info("üîç Cleaning files not referenced by any chats...")
        if not args.dry_run:
            result = cleanup_orphaned_files_by_reference()
            cleanup_results["orphaned_files_by_reference"] = result
            logger.info(f"‚úì Reference-based file cleanup: {result}")
        else:
            logger.info("‚úì [DRY RUN] Would clean files not referenced by any chats")

        # 2b. Aggressive chat file cleanup (optional - only if explicitly enabled)
        # This is disabled by default to prevent issues with cloned chats
        # if getattr(args, 'aggressive_cleanup', False):
        #     logger.info("üîç Aggressive chat files cleanup...")
        #     if not args.dry_run:
        #         result = cleanup_orphaned_chat_files()
        #         cleanup_results["chat_files"] = result
        #         logger.info(f"‚úì Chat files cleanup: {result}")
        #     else:
        #         logger.info("‚úì [DRY RUN] Would clean orphaned chat files")

        # 3. Clean up old chat collections to prevent uncontrolled growth
        collection_cleanup_days = int(
            os.getenv("VECTOR_DB_COLLECTION_CLEANUP_DAYS", "1")
        )
        logger.info(
            f"üîç Cleaning chat collections older than {collection_cleanup_days} days..."
        )
        if not args.dry_run:
            result = cleanup_old_chat_collections(max_age_days=collection_cleanup_days)
            cleanup_results["old_collections"] = result
            logger.info(f"‚úì Old collections cleanup: {result}")
        else:
            logger.info(
                f"‚úì [DRY RUN] Would clean chat collections older than {collection_cleanup_days} days"
            )

        # 4. Clean up expired chats if enabled
        if CHAT_LIFETIME_ENABLED:
            logger.info(
                f"üîç Cleaning expired chats older than {CHAT_LIFETIME_DAYS} days..."
            )
            if not args.dry_run:
                result = cleanup_expired_chats(max_age_days=CHAT_LIFETIME_DAYS)
                cleanup_results["expired_chats"] = result
                logger.info(f"‚úì Expired chats cleanup: {result}")
            else:
                logger.info(
                    f"‚úì [DRY RUN] Would clean expired chats older than {CHAT_LIFETIME_DAYS} days"
                )
        else:
            logger.info("‚è≠Ô∏è  Chat lifetime cleanup disabled - skipping")

        # 5. Clean up expired web search results
        logger.info(
            f"üîç Cleaning web search results older than {web_search_expiry_days} days..."
        )
        if not args.dry_run:
            result = cleanup_expired_web_searches(max_age_days=web_search_expiry_days)
            cleanup_results["web_searches"] = result
            logger.info(f"‚úì Web search cleanup: {result}")
        else:
            logger.info(
                f"‚úì [DRY RUN] Would clean web searches older than {web_search_expiry_days} days"
            )

        # Summary
        if not args.dry_run:
            total_cleaned = sum(
                result.get("collections_cleaned", 0) + 
                result.get("files_deleted", 0) + 
                result.get("chats_deleted", 0)
                for result in cleanup_results.values()
                if isinstance(result, dict)
            )
            logger.info(
                f"üéâ Cleanup completed successfully! Total items cleaned: {total_cleaned}"
            )

            # Log detailed results
            for operation, result in cleanup_results.items():
                if isinstance(result, dict) and result.get("status") != "error":
                    logger.info(f"   {operation}: {result}")
        else:
            logger.info("üéâ Dry run completed successfully!")

        return 0

    except ImportError as e:
        logger.error(f"‚ùå Failed to import required modules: {e}")
        logger.error(
            "Make sure the app is properly deployed and dependencies are available"
        )
        return 1

    except Exception as e:
        logger.error(f"‚ùå Cleanup failed with error: {e}")
        import traceback

        logger.error(f"Traceback: {traceback.format_exc()}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
