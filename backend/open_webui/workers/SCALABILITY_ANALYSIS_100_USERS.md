# Scalability Analysis: 100 Concurrent Users on OpenShift

## ‚ùå **CRITICAL ISSUES - WILL CAUSE FAILURES**

### 1. **Database Connection Pool Exhaustion (CRITICAL)**
**Current Configuration:**
```python
DATABASE_POOL_SIZE = 0  # Default: NO POOLING!
DATABASE_POOL_MAX_OVERFLOW = 0
```

**Problem:**
- With `pool_size=0`, SQLAlchemy uses `NullPool`, creating a **new database connection for EVERY request**
- Each file upload/job creates multiple DB connections (AppConfig, file metadata, user lookup, etc.)
- **100 concurrent users √ó 3-5 DB operations each = 300-500 simultaneous connections**
- PostgreSQL default `max_connections` is typically **100-200**, will be **EXCEEDED IMMEDIATELY**

**Impact:**
- ‚ùå Database connection limit exceeded errors
- ‚ùå Requests will fail with "too many connections"
- ‚ùå System will become unresponsive
- ‚ùå Jobs will fail to enqueue or process

**Fix Required:**
```bash
# Set in environment or ConfigMap
DATABASE_POOL_SIZE=20          # Base pool size
DATABASE_POOL_MAX_OVERFLOW=10  # Allow temporary overflow
```

**With 100 users, you need:**
- **Estimated required pool size**: 30-50 connections
- **Formula**: (Concurrent Users √ó Avg DB Operations per Request) / Worker Threads + Buffer
- **Recommendation**: Start with `DATABASE_POOL_SIZE=30, DATABASE_POOL_MAX_OVERFLOW=20`

---

### 2. **Insufficient RQ Worker Capacity (CRITICAL)**
**Current Configuration:**
```yaml
# kubernetes/manifest/base/rq-worker-deployment.yaml
replicas: 1  # Only 1 worker!
```

**Problem:**
- Each RQ worker processes **1 job at a time** (single-threaded)
- File processing jobs take **30 seconds to 10 minutes** each (embeddings, large files)
- **100 concurrent file uploads = 100 jobs in queue**
- With 1 worker: **100 √ó 5 minutes average = 500 minutes (8+ hours) queue time**

**Impact:**
- ‚ùå Users wait hours for file processing
- ‚ùå Jobs queue up and timeout (1 hour timeout)
- ‚ùå Redis queue fills up
- ‚ùå Poor user experience, possible job failures

**Fix Required:**
```yaml
# Scale workers based on load
replicas: 10  # For 100 concurrent users, need 10-20 workers
```

**Calculation:**
- **Target processing time**: < 5 minutes per job
- **Average job duration**: 2-5 minutes
- **Concurrent users**: 100
- **Required workers**: 100 / (5 min / 2 min per worker) = **40 workers**
- **Realistic minimum**: **10-20 workers** (assuming not all 100 upload simultaneously)

---

### 3. **Worker Redis Connection Pool Too Small**
**Current Configuration:**
```python
# start_worker.py:117
max_connections=10  # Per worker
```

**Problem:**
- Each worker has 10 Redis connections
- With 10 workers: **10 √ó 10 = 100 connections just for workers**
- Main app pool: **100 connections**
- **Total: 200 Redis connections** (may be fine, but tight)

**Impact:**
- ‚ö†Ô∏è Potential Redis connection limit if scaled further
- ‚ö†Ô∏è Worker connections are mostly idle (workers use 1 connection each)

**Fix:**
- Current setting is acceptable but monitor
- Consider reducing to `max_connections=5` per worker (workers need 1-2 connections)

---

### 4. **Main App Redis Pool May Be Insufficient**
**Current Configuration:**
```python
REDIS_MAX_CONNECTIONS = 100  # Default
```

**Problem:**
- 100 concurrent users on **1 webui replica**
- Each user upload triggers: lock acquisition, job enqueue, cache lookups
- **100 users √ó 2-3 Redis operations = 200-300 concurrent Redis operations**
- Pool of 100 may cause **connection waits** under peak load

**Impact:**
- ‚ö†Ô∏è Slower response times during peak load
- ‚ö†Ô∏è Possible connection timeout errors

**Fix Required:**
```bash
REDIS_MAX_CONNECTIONS=200  # Increase for 100 concurrent users
```

**OR scale webui replicas:**
```yaml
replicas: 3  # Distribute load across pods
# Each pod: 100 connections / 3 = ~33 connections per pod
```

---

### 5. **No Database Connection Cleanup in Workers (CRITICAL)**
**Current Issue:**
- Worker creates `AppConfig()` per job ‚Üí creates DB connections
- No explicit cleanup ‚Üí connections leak
- With 100 jobs, **100+ leaked connections**

**Impact:**
- ‚ùå Connection pool exhaustion even with proper pool size
- ‚ùå Memory leaks
- ‚ùå System degradation over time

**Fix:** See ISSUES_AND_RECOMMENDATIONS.md

---

## ‚ö†Ô∏è **HIGH PRIORITY ISSUES**

### 6. **AppConfig Initialization Per Job**
**Problem:**
- Each job creates `AppConfig()` which queries database
- 100 jobs = 100 database queries just for config
- Slows down job processing

**Impact:**
- Slower job processing
- Extra database load
- Poor performance

---

### 7. **Embedding Model Reinitialization**
**Problem:**
- Heavy models (SentenceTransformer) loaded per job
- 100 jobs = 100 model loads = **HUGE memory usage**

**Impact:**
- Memory exhaustion
- Slow job startup
- Possible OOM kills

---

### 8. **Single WebUI Replica**
**Current Configuration:**
```yaml
replicas: 1  # All 100 users hit same pod
```

**Problem:**
- All 100 users served by 1 pod
- Single point of failure
- No load distribution

**Recommendation:**
```yaml
replicas: 3  # Distribute load
```

---

## üìä **RESOURCE REQUIREMENTS SUMMARY**

### Current Setup (WILL FAIL):
```
WebUI Pods: 1
Workers: 1
DB Pool Size: 0 (NO POOLING)
Redis Connections: 100 (main) + 10 (worker)
```

### Required Setup for 100 Concurrent Users:
```
WebUI Pods: 3-5 replicas
Workers: 10-20 replicas
DB Pool Size: 30-50 connections
DB Max Overflow: 20 connections
Redis Connections: 200 (main) + 50 (workers)
```

---

## üéØ **IMMEDIATE ACTION ITEMS**

### Priority 1 (Fix Before Deployment):
1. ‚úÖ Set `DATABASE_POOL_SIZE=30`
2. ‚úÖ Set `DATABASE_POOL_MAX_OVERFLOW=20`
3. ‚úÖ Scale RQ workers to `replicas: 10`
4. ‚úÖ Add database connection cleanup in workers
5. ‚úÖ Cache AppConfig at worker startup

### Priority 2 (Performance):
6. ‚úÖ Increase `REDIS_MAX_CONNECTIONS=200`
7. ‚úÖ Scale WebUI to `replicas: 3`
8. ‚úÖ Cache embedding models at worker startup

### Priority 3 (Monitoring):
9. ‚úÖ Add connection pool metrics
10. ‚úÖ Monitor Redis connection usage
11. ‚úÖ Monitor database connection pool usage
12. ‚úÖ Add job queue length alerts

---

## üìà **EXPECTED BEHAVIOR WITH FIXES**

### With Proper Configuration:
- ‚úÖ 100 concurrent file uploads: **Queue in Redis, processed within 5-10 minutes**
- ‚úÖ Database connections: **Pooled, reused, no exhaustion**
- ‚úÖ Redis connections: **Within limits, properly managed**
- ‚úÖ Worker capacity: **10-20 jobs processed simultaneously**
- ‚úÖ User experience: **Files process in reasonable time**

### Without Fixes:
- ‚ùå 100 concurrent uploads: **Database connection errors, jobs fail**
- ‚ùå Queue time: **Hours or days**
- ‚ùå System: **Unresponsive, crashes**
- ‚ùå User experience: **Terrible, errors everywhere**

---

## üîß **RECOMMENDED CONFIGURATION VALUES**

### Environment Variables (ConfigMap/Secrets):
```yaml
# Database Pooling (CRITICAL)
DATABASE_POOL_SIZE: "30"
DATABASE_POOL_MAX_OVERFLOW: "20"
DATABASE_POOL_TIMEOUT: "30"
DATABASE_POOL_RECYCLE: "3600"

# Redis Configuration
REDIS_MAX_CONNECTIONS: "200"

# Job Queue Configuration
JOB_TIMEOUT: "3600"  # 1 hour
JOB_MAX_RETRIES: "3"
JOB_RETRY_DELAY: "60"
```

### Kubernetes Deployment Scaling:
```yaml
# webui-deployment.yaml
replicas: 3

# rq-worker-deployment.yaml
replicas: 10  # Start with 10, scale to 20 if needed
```

---

## üß™ **LOAD TESTING RECOMMENDATIONS**

1. **Test with 10 users first** - Verify fixes work
2. **Gradually increase to 50 users** - Monitor connection pools
3. **Scale to 100 users** - Verify all systems stable
4. **Monitor:**
   - Database connection pool usage
   - Redis connection count
   - Job queue length
   - Worker processing rate
   - Error rates

---

## üö® **RED FLAGS TO WATCH FOR**

- Database connection errors: "too many connections"
- Redis connection timeouts
- Job queue length > 50 jobs
- Worker CPU/Memory > 80%
- Job processing time > 10 minutes
- Error rate > 5%

