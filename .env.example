# Ollama URL for the backend to connect
# The path '/ollama' will be redirected to the specified backend URL
OLLAMA_BASE_URL='http://localhost:11434'

OPENAI_API_BASE_URL=''
OPENAI_API_KEY=''

# AUTOMATIC1111_BASE_URL="http://localhost:7860"

# For production, you should only need one host as
# fastapi serves the svelte-kit built frontend and backend from the same host and port.
# To test with CORS locally, you can set something like
# CORS_ALLOW_ORIGIN='http://localhost:5173;http://localhost:8080'
CORS_ALLOW_ORIGIN='*'

# For production you should set this to match the proxy configuration (127.0.0.1)
FORWARDED_ALLOW_IPS='*'

# DO NOT TRACK
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false

# Chat encryption (client-side, at-rest)
# When enabled, chat content is encrypted in the browser and only ciphertext is stored on the server.
# Note: this does not encrypt prompts sent to the backend for model inference.
WEBUI_CHAT_ENCRYPTION_DEFAULT=false
WEBUI_CHAT_ENCRYPTION_REQUIRED=false
WEBUI_CHAT_ENCRYPTION_ALLOW_LEGACY_READ=true
