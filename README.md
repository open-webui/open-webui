# VITA - Vailen Industries Thematic AI â˜•

**VITA (Vailen Industries Thematic AI)** is a powerful, coffee-inspired AI platform with native support for Claude, OpenAI, Ollama, and MCP (Model Context Protocol). Built on Open WebUI, VITA adds enhanced agentic capabilities and a warm, intuitive interface.

![VITA Demo](./demo.gif)

## What is VITA? â­

VITA stands for **Vailen Industries Thematic AI** - a fork of Open WebUI enhanced with:
- â˜• **Coffee-themed UI** - Warm, rich colors inspired by your favorite brew
- ğŸ¤– **Native Claude Support** - First-class integration with Anthropic's Claude models
- ğŸ”— **MCP Integration** - Full Model Context Protocol support for agentic workflows
- ğŸš€ **Enhanced Features** - Multi-step tool execution and advanced AI capabilities

## Key Features â­

- â˜• **Coffee-Themed Interface**: A warm, inviting UI with rich coffee-inspired colors

- ğŸ¤– **Native Claude/Anthropic Support**: Direct integration with Claude models, no proxy needed
  - Optimal tool calling with Anthropic's native format
  - Support for prompt caching and extended thinking
  - Streaming and non-streaming responses

- ğŸ”— **MCP (Model Context Protocol) Integration**: Full support for agentic workflows
  - Multi-step tool execution
  - Native integration with Claude's tool use
  - Support for MCP resources and prompts

- ğŸš€ **Effortless Setup**: Install seamlessly using Docker or Kubernetes (kubectl, kustomize or helm) for a hassle-free experience with support for both `:ollama` and `:cuda` tagged images.

- ğŸ¤ **Multi-Provider Support**: Effortlessly integrate OpenAI, Claude/Anthropic, Ollama, and OpenAI-compatible APIs. Customize API URLs to work with **LMStudio, GroqCloud, Mistral, OpenRouter, and more**.

- ğŸ›¡ï¸ **Granular Permissions and User Groups**: By allowing administrators to create detailed user roles and permissions, we ensure a secure user environment. This granularity not only enhances security but also allows for customized user experiences, fostering a sense of ownership and responsibility amongst users.

- ğŸ”„ **SCIM 2.0 Support**: Enterprise-grade user and group provisioning through SCIM 2.0 protocol, enabling seamless integration with identity providers like Okta, Azure AD, and Google Workspace for automated user lifecycle management.

- ğŸ“± **Responsive Design**: Enjoy a seamless experience across Desktop PC, Laptop, and Mobile devices.

- ğŸ“± **Progressive Web App (PWA) for Mobile**: Enjoy a native app-like experience on your mobile device with our PWA, providing offline access on localhost and a seamless user interface.

- âœ’ï¸ğŸ”¢ **Full Markdown and LaTeX Support**: Elevate your LLM experience with comprehensive Markdown and LaTeX capabilities for enriched interaction.

- ğŸ¤ğŸ“¹ **Hands-Free Voice/Video Call**: Experience seamless communication with integrated hands-free voice and video call features, allowing for a more dynamic and interactive chat environment.

- ğŸ› ï¸ **Model Builder**: Easily create Ollama models via the Web UI. Create and add custom characters/agents, customize chat elements, and import models effortlessly.

- ğŸ **Native Python Function Calling Tool**: Enhance your LLMs with built-in code editor support in the tools workspace. Bring Your Own Function (BYOF) by simply adding your pure Python functions, enabling seamless integration with LLMs.

- ğŸ“š **Local RAG Integration**: Dive into the future of chat interactions with groundbreaking Retrieval Augmented Generation (RAG) support. This feature seamlessly integrates document interactions into your chat experience. You can load documents directly into the chat or add files to your document library, effortlessly accessing them using the `#` command before a query.

- ğŸ” **Web Search for RAG**: Perform web searches using providers like `SearXNG`, `Google PSE`, `Brave Search`, `serpstack`, `serper`, `Serply`, `DuckDuckGo`, `TavilySearch`, `SearchApi` and `Bing` and inject the results directly into your chat experience.

- ğŸŒ **Web Browsing Capability**: Seamlessly integrate websites into your chat experience using the `#` command followed by a URL. This feature allows you to incorporate web content directly into your conversations, enhancing the richness and depth of your interactions.

- ğŸ¨ **Image Generation Integration**: Seamlessly incorporate image generation capabilities using options such as AUTOMATIC1111 API or ComfyUI (local), and OpenAI's DALL-E (external), enriching your chat experience with dynamic visual content.

- âš™ï¸ **Many Models Conversations**: Effortlessly engage with various models simultaneously, harnessing their unique strengths for optimal responses. Enhance your experience by leveraging a diverse set of models in parallel.

- ğŸ” **Role-Based Access Control (RBAC)**: Ensure secure access with restricted permissions; only authorized individuals can access your models, and exclusive model creation/pulling rights are reserved for administrators.

- ğŸŒğŸŒ **Multilingual Support**: Experience VITA in your preferred language with our internationalization (i18n) support.

- ğŸ§© **Pipelines Plugin Support**: Seamlessly integrate custom logic and Python libraries into VITA using Pipelines Plugin Framework. Launch your Pipelines instance and explore endless possibilities including **Function Calling**, **Rate Limiting**, **Usage Monitoring**, **Live Translation**, **Toxic Message Filtering** and much more.

- ğŸŒŸ **Continuous Updates**: We are committed to improving VITA with regular updates, fixes, and new features.

## Quick Start ğŸš€

### Docker Setup

```bash
# With Ollama
docker run -d -p 3000:8080 \
  --add-host=host.docker.internal:host-gateway \
  -v open-webui:/app/backend/data \
  --name vita \
  --restart always \
  ghcr.io/open-webui/open-webui:main

# Standalone (bring your own APIs)
docker run -d -p 3000:8080 \
  -v open-webui:/app/backend/data \
  --name vita \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```

### Configuration

Set your API keys via environment variables:

```bash
# For Claude/Anthropic
export ENABLE_ANTHROPIC_API=true
export ANTHROPIC_API_KEY="sk-ant-..."

# For OpenAI
export ENABLE_OPENAI_API=true
export OPENAI_API_KEY="sk-..."

# For Ollama (local)
export ENABLE_OLLAMA_API=true
export OLLAMA_API_BASE_URL="http://localhost:11434/api"
```

## VITA-Specific Features

### Native Claude Support

VITA includes native support for Anthropic's Claude models:
- Direct API integration (no proxy needed)
- Optimal tool calling performance
- Support for all Claude 3 and 3.5 models
- Streaming responses with proper SSE formatting

### MCP Integration

Full Model Context Protocol support:
- Multi-step agentic workflows
- Tool execution with iteration controls
- Support for MCP resources and prompts
- OAuth 2.1 authentication for MCP servers

### Coffee Theme

A warm, inviting color scheme inspired by coffee:
- Rich espresso darks
- Creamy latte lights
- Smooth cappuccino accents
- Designed for extended coding and chat sessions

## Built On Open WebUI

VITA is built on the excellent [Open WebUI](https://github.com/open-webui/open-webui) project. We're grateful to the Open WebUI team and community for creating such a solid foundation.

### Changes from Open WebUI:
- Native Anthropic/Claude API integration
- MCP (Model Context Protocol) support
- Coffee-themed UI redesign
- Enhanced agentic capabilities

## Development

```bash
# Clone the repository
git clone https://github.com/sparioendernerd/VITA-webui.git
cd VITA-webui

# Install dependencies
npm install

# Set up Python backend
cd backend
pip install -r requirements.txt

# Run development server
npm run dev
```

## Contributing

VITA is a personal fork focused on MCP integration and enhanced Claude support. If you'd like to contribute to the base project, please visit [Open WebUI](https://github.com/open-webui/open-webui).

## License

VITA inherits the MIT License from Open WebUI. See LICENSE file for details.

## Acknowledgments

- **Open WebUI Team** - For the excellent foundation
- **Anthropic** - For Claude and the MCP protocol
- **Coffee** - For the inspiration â˜•

---

**Powered by coffee and AI** â˜•ğŸ¤–
