apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-webui-rq-worker-deployment
  namespace: rit-genai-naga-dev  # Update to your namespace
  labels:
    app: open-webui-rq-worker
    app.kubernetes.io/component: rq-worker
    app.kubernetes.io/instance: open-webui
spec:
  replicas: 8  # Start with 8 workers for 100 concurrent users (adjust as needed)
  selector:
    matchLabels:
      app: open-webui-rq-worker
  template:
    metadata:
      labels:
        app: open-webui-rq-worker
        app.kubernetes.io/component: rq-worker
        app.kubernetes.io/instance: open-webui
    spec:
      # Use same service account as main deployment (if needed for image pull)
      serviceAccountName: open-webui
      # Image pull secrets (if your registry requires authentication)
      # Uncomment and update if needed:
      # imagePullSecrets:
      #   - name: open-webui-dockercfg-6jhfz  # Update to your actual pull secret name
      
      containers:
      - name: rq-worker
        # Same image as main Open WebUI deployment
        image: registry.cloud.rt.nyu.edu/rit-genai-poc/naga-open-webui:latest
        imagePullPolicy: Always
        # Override the default command to start the worker instead of uvicorn
        # Set PYTHONPATH so Python can find the open_webui module
        command: ["/bin/bash", "-c", "cd /app/backend && PYTHONPATH=/app/backend:$PYTHONPATH python -m open_webui.workers.start_worker"]
        env:
        # Redis configuration (REQUIRED)
        # Note: redis-config ConfigMap only contains redis.conf, NOT REDIS_URL
        # So we set REDIS_URL directly with the password
        - name: REDIS_URL
          value: "redis://:DaSharedBrainsxDxD2020@redis.rit-genai-naga-dev.svc.cluster.local:6379/0"
        
        # WebSocket Redis (Recommended for multi-replica support)
        - name: WEBSOCKET_REDIS_URL
          value: "redis://:DaSharedBrainsxDxD2020@redis.rit-genai-naga-dev.svc.cluster.local:6379/0"
        
        - name: WEBSOCKET_MANAGER
          value: "redis"
        
        # Job queue configuration (REQUIRED)
        - name: ENABLE_JOB_QUEUE
          value: "True"  # Must be True for worker to start
        - name: JOB_TIMEOUT
          value: "3600"  # 1 hour default
        - name: JOB_MAX_RETRIES
          value: "3"
        - name: JOB_RETRY_DELAY
          value: "60"
        - name: JOB_RESULT_TTL
          value: "3600"
        - name: JOB_FAILURE_TTL
          value: "86400"
        
        # Database configuration (REQUIRED - worker needs DB access)
        # Set directly as value (same as main deployment)
        - name: DATABASE_URL
          value: "postgresql://rit-genai-naga-dev-admin:isF%3CrB%5D6S0ml70%7CDi8%2AU%5B1K3@rit-genai-naga-dev-primary.rit-genai-naga-dev.svc:5432/pilotgenai_dev_pg?sslmode=require&sslcert=&sslkey=&sslrootcert="
        
        # Database Pool Configuration (for 100 max_connections)
        # Main deployment: 3 web pods × (25+10=35) = 105 connections (exceeds 100, but uses overflow)
        # Workers: 8 workers × (5+2=7) = 56 connections
        # Total: ~161 connections potential, but with connection reuse and proper cleanup, should work
        # Note: Main deployment uses 25+10, workers use smaller pools (5+2) to reduce total
        - name: DATABASE_POOL_SIZE
          value: "5"  # 5 base connections per worker (smaller than main deployment's 25)
        - name: DATABASE_POOL_MAX_OVERFLOW
          value: "2"  # 2 overflow connections per worker (7 max per worker, vs main's 35)
        - name: DATABASE_POOL_TIMEOUT
          value: "30"
        - name: DATABASE_POOL_RECYCLE
          value: "3600"
        
        # Redis Connection Pool
        - name: REDIS_MAX_CONNECTIONS
          value: "100"  # Same as main deployment - shared across all pods
        
        # Super Admin Email Configuration (for access control)
        - name: SUPER_ADMIN_EMAILS
          value: "sm11538@nyu.edu,ms15138@nyu.edu,mb484@nyu.edu,cg4532@nyu.edu,ht2490@nyu.edu,ps5226@nyu.edu"
        
        # Vector DB configuration (REQUIRED - worker needs vector DB access)
        - name: VECTOR_DB
          value: "pgvector"  # or "chroma" or "qdrant"
        
        # Embedding configuration
        - name: RAG_EMBEDDING_ENGINE
          value: "portkey"  # or "openai" or "ollama"
        - name: RAG_EMBEDDING_MODEL
          value: "@openai-embedding/text-embedding-3-small"
        
        # Logging configuration
        - name: WORKER_LOG_LEVEL
          value: "INFO"  # Can be DEBUG for verbose logging
        - name: GLOBAL_LOG_LEVEL
          value: "INFO"
        
        # Timezone (same as main deployment)
        - name: TZ
          value: "America/New_York"
        
        # Vector DB configuration (same as main deployment)
        - name: PGVECTOR_INITIALIZE_MAX_VECTOR_LENGTH
          value: "1536"
        
        # Add any other environment variables needed by the worker
        # (e.g., TIKA_SERVER_URL, DOCUMENT_INTELLIGENCE_ENDPOINT, etc.)
        
        resources:
          requests:
            cpu: "250m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "2Gi"
        
        volumeMounts:
        - name: webui-volume
          mountPath: /app/backend/data
          readOnly: false  # Worker may need to write temp files
        
        # Liveness probe to detect worker crashes
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "pgrep -f 'open_webui.workers.start_worker' || exit 1"
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        
        # Readiness probe
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "pgrep -f 'open_webui.workers.start_worker' || exit 1"
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
      
      volumes:
      - name: webui-volume
        persistentVolumeClaim:
          claimName: open-webui  # PVC name from your deployment (not open-webui-pvc)
      restartPolicy: Always

