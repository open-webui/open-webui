ollama:
  resources:
    requests:
      cpu: "2000m"
      memory: "2Gi"
    limits:
      cpu: "4000m"
      memory: "4Gi"
      nvidia.com/gpu: "0"
  service:
    type: ClusterIP
  gpu:
    enabled: false

webui:
  resources:
    requests:
      cpu: "500m"
      memory: "500Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"
  ingress:
    enabled: true
    host: open-webui.minikube.local
  service:
    type: NodePort
