# =============================================================================
# mAI Production Environment Template
# =============================================================================
# Copy this file to .env and customize for each client instance
# Generated: $(date +%Y-%m-%d)

# =============================================================================
# Client-Specific Configuration
# =============================================================================
# TODO: Replace with actual client values
ORGANIZATION_NAME=CLIENT_ORGANIZATION_NAME
SPENDING_LIMIT=unlimited

# =============================================================================
# OpenRouter Configuration (Client-specific API key required)
# =============================================================================
# TODO: Replace with client's OpenRouter API key
OPENROUTER_API_KEY=sk-or-v1-YOUR_CLIENT_API_KEY_HERE
OPENROUTER_HOST=https://openrouter.ai/api/v1
# TODO: Replace with client-specific external user ID
OPENROUTER_EXTERNAL_USER=mai_client_UNIQUE_ID

# =============================================================================
# OpenRouter Model Filtering (Production Configuration - 12 specific models)
# =============================================================================
# This configuration restricts OpenRouter to exactly 12 approved models
# DO NOT MODIFY unless updating across ALL client instances
OPENAI_API_CONFIGS='{"0":{"enable":true,"connection_type":"external","model_ids":["anthropic/claude-sonnet-4","google/gemini-2.5-flash","google/gemini-2.5-pro","deepseek/deepseek-chat-v3-0324","anthropic/claude-3.7-sonnet","google/gemini-2.5-flash-lite-preview-06-17","openai/gpt-4.1","x-ai/grok-4","openai/gpt-4o-mini","openai/o4-mini-high","openai/o3","openai/chatgpt-4o-latest"],"tags":["openrouter"],"prefix_id":null}}'

# =============================================================================
# mAI Application Configuration
# =============================================================================

# API Configuration
OLLAMA_BASE_URL='http://localhost:11434'
OPENAI_API_BASE_URL=''
OPENAI_API_KEY=''

# CORS and Networking
CORS_ALLOW_ORIGIN='http://localhost:5173;http://localhost:8080;http://127.0.0.1:5173;http://127.0.0.1:8080'
FORWARDED_ALLOW_IPS='*'

# Application URLs (Customize ports for each client)
# TODO: Update ports for client-specific deployment
WEBUI_URL=http://localhost:5173
BACKEND_URL=http://localhost:8080

# Privacy and Telemetry
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false
USER_AGENT=mAI/0.6.16 (Open-WebUI-Fork)

# =============================================================================
# Production Deployment Notes
# =============================================================================
# 1. Each client instance should have unique:
#    - ORGANIZATION_NAME
#    - OPENROUTER_API_KEY  
#    - OPENROUTER_EXTERNAL_USER
#    - Port numbers (if on same server)
#
# 2. The OPENAI_API_CONFIGS should remain identical across all instances
#    for consistent model availability
#
# 3. Use scripts/production/deploy_model_filtering.py for updates
#
# 4. Always test configuration with:
#    python scripts/production/model_filtering_config.py --validate-json "$OPENAI_API_CONFIGS"